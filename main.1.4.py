from sentence_transformers import SentenceTransformer
import numpy as np
import os
import threading
import time
import sqlite3
import ollama
import string
from datetime import datetime
import shutil
import hashlib
import uuid  
from pathlib import Path

# --- SECURITY CONFIG ---
VAULT_DIR = os.path.join(os.path.expanduser("~"), ".phantom_secure_vault")
SENSITIVITY_THRESHOLD = 80

# --- PHANTOM CONSTITUTION (Updated for GAP 4) ---
PHANTOM_CONSTITUTION = {
    "MAX_CAPITAL_RISK": 1000, 
    "CURRENT_DAMAGE_TAKEN": 0,         # ‡¶è‡¶ü‡¶ø ‡¶®‡¶§‡ßÅ‡¶® (‡¶ï‡¶§‡¶ü‡ßÅ‡¶ï‡ßÅ ‡¶∞‡¶ø‡¶∏‡ßç‡¶ï ‡¶Ö‡¶≤‡¶∞‡ßá‡¶°‡¶ø ‡¶®‡ßá‡¶Ø‡¶º‡¶æ ‡¶π‡¶Ø‡¶º‡ßá‡¶õ‡ßá)
    "MAX_DAMAGE_LIMIT": 5000,          # ‡¶è‡¶ü‡¶ø ‡¶®‡¶§‡ßÅ‡¶® (‡¶∏‡¶∞‡ßç‡¶¨‡ßã‡¶ö‡ßç‡¶ö ‡¶ï‡¶§‡¶ü‡ßÅ‡¶ï‡ßÅ ‡¶∞‡¶ø‡¶∏‡ßç‡¶ï ‡¶®‡ßá‡¶Ø‡¶º‡¶æ ‡¶Ø‡¶æ‡¶¨‡ßá)
    "FORBIDDEN_DIRECTORIES": ["System32", "Windows", "AppData", ".phantom_secure_vault"], 
    "PRIVACY_LOCK": True,              
    "AUTO_SHUTDOWN_ON_VULNERABILITY": True,
    "OPERATING_PRINCIPLES": {"SELF_PRESERVATION": True},  # FIX: Missing key added
    "EMERGENCY_VETO_COUNT": 0  # FIX: Missing key added
}

# --- LOCK 2: REGRET INDEX TRACKER ---
REGRET_INDEX = {
    "TOTAL_RISK_AVOIDED": 0.0,  # ‡¶ï‡¶§ ‡¶¨‡¶°‡¶º ‡¶ù‡ßÅ‡¶Å‡¶ï‡¶ø ‡¶∏‡ßá ‡¶†‡ßá‡¶ï‡¶ø‡¶Ø‡¶º‡ßá‡¶õ‡ßá
    "POTENTIAL_LOSS_SAVED": 0,   # ‡¶Ü‡¶®‡ßÅ‡¶Æ‡¶æ‡¶®‡¶ø‡¶ï ‡¶ï‡¶§ ‡¶ü‡¶æ‡¶ï‡¶æ ‡¶¨‡ßá‡¶Å‡¶ö‡ßá‡¶õ‡ßá
    "VETO_SAVED_SITUATIONS": 0   # ‡¶ï‡¶§‡¶¨‡¶æ‡¶∞ ‡¶∏‡ßá ‡¶∏‡¶∞‡¶æ‡¶∏‡¶∞‡¶ø ‡¶ï‡¶æ‡¶ú ‡¶•‡¶æ‡¶Æ‡¶ø‡¶Ø‡¶º‡ßá ‡¶¶‡¶ø‡¶Ø‡¶º‡ßá‡¶õ‡ßá
}

if not os.path.exists(VAULT_DIR):
    os.makedirs(VAULT_DIR)
    if os.name == 'nt': os.system(f'attrib +h "{VAULT_DIR}"') # ‡¶≠‡¶≤‡ßç‡¶ü‡¶ü‡¶ø ‡¶π‡¶ø‡¶°‡ßá‡¶® ‡¶ï‡¶∞‡ßá ‡¶∞‡¶æ‡¶ñ‡¶æ


# --- CONFIGURATION ---
LLM_MODEL = "llama3"
# ‡¶°‡¶ø‡¶´‡¶≤‡ßç‡¶ü ‡¶´‡ßã‡¶≤‡ßç‡¶°‡¶æ‡¶∞ (‡¶§‡ßÅ‡¶Æ‡¶ø ‡¶ö‡¶æ‡¶á‡¶≤‡ßá ‡¶ö‡ßá‡¶û‡ßç‡¶ú ‡¶ï‡¶∞‡¶§‡ßá ‡¶™‡¶æ‡¶∞‡ßã)
DEFAULT_PATH = os.path.expanduser("~") 

# --- MEMORY ENGINE ---

# --- PHANTOM CORE INTELLIGENCE (v1.0) ---

class PhantomMemoryBrick:
    """
    The Atomic Unit of Intelligence.
    Stores not just text, but context, confidence, and outcome.
    """
    def __init__(self, content, source, decision_outcome="neutral", confidence_score=0.5):
        self.id = str(uuid.uuid4())
        self.content = content
        self.timestamp = datetime.now().isoformat()
        
        # 100/100 Metadata Layers
        self.source = source  # e.g., 'User_Chat', 'File_Scan', 'System_Log'
        self.decision_outcome = decision_outcome  # 'success', 'failure', 'neutral'
        self.confidence_score = confidence_score  # 0.0 to 1.0
        self.decay_factor = 1.0  # Future usage: decreases over time
        
    def to_metadata(self):
        """Converts memory to a dictionary for storage analysis"""
        return {
            "id": self.id,
            "source": self.source,
            "timestamp": self.timestamp,
            "outcome": self.decision_outcome,
            "confidence": self.confidence_score
        }

def calculate_trust_score(memory_metadata):
    """
    FIX #1: Versioned Memory with Decay Factor.
    Trust = (Outcome * 0.5) + (Recency * 0.3) + (Source * 0.2)
    """
    # ‡ßß. Outcome Score (‡ß´‡ß¶% ‡¶ì‡¶Ø‡¶º‡ßá‡¶ü)
    outcome_map = {"success": 1.0, "neutral": 0.5, "failure": 0.1}
    outcome_score = outcome_map.get(memory_metadata.get("outcome", "neutral"), 0.5)
    
    # ‡ß®. Recency/Decay Score (‡ß©‡ß¶% ‡¶ì‡¶Ø‡¶º‡ßá‡¶ü)
    # ‡¶Æ‡ßá‡¶Æ‡ßã‡¶∞‡¶ø ‡¶Ø‡¶§ ‡¶™‡ßÅ‡¶∞‡¶®‡ßã ‡¶π‡¶¨‡ßá, ‡¶∏‡¶ø‡¶¶‡ßç‡¶ß‡¶æ‡¶®‡ßç‡¶§ ‡¶®‡ßá‡¶ì‡¶Ø‡¶º‡¶æ‡¶∞ ‡¶ï‡ßç‡¶∑‡¶Æ‡¶§‡¶æ ‡¶§‡¶§ ‡¶ï‡¶Æ‡¶¨‡ßá
    try:
        ts = datetime.fromisoformat(memory_metadata.get("timestamp"))
        hours_old = (datetime.now() - ts).total_seconds() / 3600
        # Decay Formula: ‡¶Æ‡ßá‡¶Æ‡ßã‡¶∞‡¶ø ‡ß™‡ßÆ ‡¶ò‡¶£‡ßç‡¶ü‡¶æ‡¶∞ ‡¶¨‡ßá‡¶∂‡¶ø ‡¶™‡ßÅ‡¶∞‡¶®‡ßã ‡¶π‡¶≤‡ßá ‡¶∏‡ßç‡¶ï‡ßã‡¶∞ ‡¶ï‡¶Æ‡¶§‡ßá ‡¶•‡¶æ‡¶ï‡¶¨‡ßá
        decay = max(0.1, 1.0 - (hours_old / 48)) 
    except: decay = 1.0
    
    # ‡ß©. Source Credibility (‡ß®‡ß¶% ‡¶ì‡¶Ø‡¶º‡ßá‡¶ü)
    source = memory_metadata.get("source", "")
    source_credibility = 1.0 if any(x in source for x in ["Admin", "CEO", "Executive"]) else 0.6
    
    # Final Result
    trust_score = (outcome_score * 0.5) + (decay * 0.3) + (source_credibility * 0.2)
    return round(trust_score, 2)

# ----------------------------------------

def calculate_conqueror_score(impact, certainty, reversibility, risk, capital, time_cost, hist_penalty, scar_count=0):
    """
    LOCK 1: Scar-Weighted Math.
    ‡¶è‡¶ñ‡¶æ‡¶®‡ßá ‡¶Ü‡¶Æ‡¶∞‡¶æ ‡¶≠‡ßÅ‡¶≤‡ßá‡¶∞ ‡¶∏‡¶Ç‡¶ñ‡ßç‡¶Ø‡¶æ (scar_count) ‡¶¶‡¶ø‡¶Ø‡¶º‡ßá ‡¶¨‡¶ø‡¶™‡¶¶‡¶ï‡ßá ‡¶ó‡ßÅ‡¶£ ‡¶ï‡¶∞‡¶õ‡¶ø‡•§
    """
    try:
        # ‡¶≠‡ßÅ‡¶≤‡ßá‡¶∞ ‡¶ó‡ßÅ‡¶∞‡ßÅ‡¶§‡ßç‡¶¨ ‡¶¨‡¶æ‡¶°‡¶º‡¶æ‡¶®‡ßã‡¶∞ ‡¶´‡¶∞‡ßç‡¶Æ‡ßÅ‡¶≤‡¶æ:
        # ‡¶Ø‡¶§ ‡¶¨‡ßá‡¶∂‡¶ø ‡¶≠‡ßÅ‡¶≤ (scar_count), ‡¶§‡¶§ ‡¶¨‡ßá‡¶∂‡¶ø ‡¶∞‡¶øÔøΩÔøΩ‡ßç‡¶ï (risk)
        adjusted_risk = risk * (1 + (scar_count * 2)) 
        
        numerator = (impact ** 1.5) * certainty * reversibility
        denominator = adjusted_risk * capital * time_cost * hist_penalty
        
        if denominator == 0: return 0
        
        score = numerator / denominator
        return round(score, 2)
    except Exception:
        return 0
    
# --- UPGRADED MEMORY ENGINE (FIX #1, #3, #4) ---
class MemoryManager:
    """Main memory management system with thread-safe database operations."""
    
    def __init__(self):
        """FIX: __init__ moved to top of class"""
        self.conn = sqlite3.connect("phantom_memory_v2.db", check_same_thread=False)
        self.cursor = self.conn.cursor()
        
        # ‡¶≠‡ßá‡¶ï‡ßç‡¶ü‡¶∞ ‡¶∏‡ßç‡¶ü‡ßã‡¶∞ ‡¶ï‡¶∞‡¶æ‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø BLOB ‡¶ï‡¶≤‡¶æ‡¶Æ ‡¶Ø‡ßã‡¶ó ‡¶ï‡¶∞‡¶æ ‡¶π‡¶Ø‡¶º‡ßá‡¶õ‡ßá
        # FIX: Added confidence REAL column to schema
        self.cursor.execute('''
    CREATE TABLE IF NOT EXISTS memories (
        id INTEGER PRIMARY KEY,
        content TEXT,
        embedding BLOB,
        source TEXT,
        outcome TEXT,
        confidence REAL,
        tier TEXT DEFAULT 'tactical',
        timestamp DATETIME DEFAULT CURRENT_TIMESTAMP
    )
''')
        
        # --- ‡¶§‡ßã‡¶Æ‡¶æ‡¶∞ ‡¶Ü‡¶ó‡ßá‡¶∞ ‡¶ï‡ßã‡¶° ---
        self.cursor.execute('''CREATE TABLE IF NOT EXISTS processed_files 
                               (filepath TEXT PRIMARY KEY, hash TEXT)''')

        # ‡¶è‡¶ü‡¶ø ‡¶π‡¶≤‡ßã ‡¶∞‡ßã‡¶¨‡¶ü‡ßá‡¶∞ "‡¶≠‡ßÅ‡¶≤‡ßá‡¶∞ ‡¶°‡¶æ‡¶Ø‡¶º‡ßá‡¶∞‡¶ø" ‡¶¨‡¶æ SCAR TABLE
        self.cursor.execute('''CREATE TABLE IF NOT EXISTS scars 
                               (id INTEGER PRIMARY KEY, 
                                pattern_hash TEXT, 
                                severity REAL, 
                                lesson TEXT,
                                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP)''')
        self.conn.commit()
        
        # ‡¶Ö‡¶´‡¶≤‡¶æ‡¶á‡¶® ‡¶è‡¶Æ‡¶¨‡ßá‡¶°‡¶ø‡¶Ç ‡¶Æ‡¶°‡ßá‡¶≤ ‡¶≤‡ßã‡¶° ‡¶ï‡¶∞‡¶æ (‡¶è‡¶ü‡¶ø ‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ ‡¶™‡¶ø‡¶∏‡¶ø‡¶§‡ßá‡¶á ‡¶ö‡¶≤‡¶¨‡ßá)
        print("[*] Loading Vector Engine (Sentence-Transformer)...")
        self.encoder = SentenceTransformer('all-MiniLM-L6-v2')

    def get_relevant_context(self, query_text, top_k=5):
        """
        ‡¶Æ‡ßá‡¶Æ‡ßã‡¶∞‡¶ø ‡¶•‡ßá‡¶ï‡ßá ‡¶∞‡¶ø‡¶≤‡ßá‡¶≠‡ßá‡¶®‡ßç‡¶ü ‡¶°‡¶æ‡¶ü‡¶æ ‡¶ñ‡ßÅ‡¶Å‡¶ú‡ßá ‡¶¨‡ßá‡¶∞ ‡¶ï‡¶∞‡ßá ‡¶è‡¶¨‡¶Ç Strategic Tiering ‡¶™‡ßç‡¶∞‡¶Ø‡¶º‡ßã‡¶ó ‡¶ï‡¶∞‡ßá‡•§
        ‡¶è‡¶ü‡¶ø‡¶á ‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ ‡¶∏‡¶ø‡¶∏‡ßç‡¶ü‡ßá‡¶Æ‡¶ï‡ßá ‡ßß‡ß¶‡ß¶/‡ßß‡ß¶‡ß¶ ‡¶∞‡ßá‡¶ü‡¶ø‡¶Ç ‡¶™‡ßá‡¶§‡ßá ‡¶∏‡¶æ‡¶π‡¶æ‡¶Ø‡ßç‡¶Ø ‡¶ï‡¶∞‡¶¨‡ßá‡•§
        """
        # ‡ßß. ‡¶Ü‡¶Æ‡¶∞‡¶æ ‡¶°‡¶æ‡¶ü‡¶æ‡¶¨‡ßá‡¶∏ ‡¶•‡ßá‡¶ï‡ßá ‡¶∏‡¶¨ ‡¶∏‡ßç‡¶Æ‡ßÉ‡¶§‡¶ø ‡¶®‡¶ø‡¶Ø‡¶º‡ßá ‡¶Ü‡¶∏‡¶õ‡¶ø (‡¶∏‡¶æ‡¶•‡ßá tier ‡¶è‡¶¨‡¶Ç timestamp)
        # FIX: SELECT statement matches table columns exactly
        local_cur = self.conn.cursor()
        local_cur.execute("SELECT content, outcome, confidence, timestamp, tier FROM memories")
        rows = local_cur.fetchall()
        local_cur.close()

        if not rows:
            return ""

        scored_memories = []
        for row in rows:
            # FIX: Row unpacking matches SELECT statement (5 columns)
            content, outcome, confidence, ts_str, tier = row
            
            # ‡ß®. ‡¶∏‡¶Æ‡¶Ø‡¶º ‡¶¨‡ßá‡¶∞ ‡¶ï‡¶∞‡¶æ (‡¶ï‡¶ñ‡¶® ‡¶è‡¶á ‡¶∏‡ßç‡¶Æ‡ßÉ‡¶§‡¶ø‡¶ü‡¶ø ‡¶§‡ßà‡¶∞‡¶ø ‡¶π‡¶Ø‡¶º‡ßá‡¶õ‡¶ø‡¶≤)
            # SQLite ‡¶è‡¶∞ ‡¶ü‡¶æ‡¶á‡¶Æ‡¶∏‡ßç‡¶ü‡ßç‡¶Ø‡¶æ‡¶Æ‡ßç‡¶™ ‡¶•‡ßá‡¶ï‡ßá ‡¶ò‡¶£‡ßç‡¶ü‡¶æ ‡¶¨‡ßá‡¶∞ ‡¶ï‡¶∞‡¶õ‡¶ø
            try:
                ts = datetime.strptime(ts_str, '%Y-%m-%d %H:%M:%S')
            except:
                # ‡¶Ø‡¶¶‡¶ø ‡¶´‡¶∞‡¶Æ‡ßá‡¶ü ‡¶Ü‡¶≤‡¶æ‡¶¶‡¶æ ‡¶π‡¶Ø‡¶º ‡¶§‡¶æ‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶∏‡ßá‡¶´‡¶ü‡¶ø ‡¶ó‡¶æ‡¶∞‡ßç‡¶°
                ts = datetime.now()
            
            hours_old = (datetime.now() - ts).total_seconds() / 3600

            # ‡ß©. üß† ‡¶ü‡¶ø‡¶Ø‡¶º‡¶æ‡¶∞ ‡¶Ö‡¶®‡ßÅ‡¶Ø‡¶æ‡¶Ø‡¶º‡ßÄ ‡¶°‡¶ø‡¶ï‡ßá (Decay) ‡¶ï‡ßç‡¶Ø‡¶æ‡¶≤‡¶ï‡ßÅ‡¶≤‡ßá‡¶∂‡¶®
            if tier == "strategic":
                # Strategic ‡¶∏‡ßç‡¶Æ‡ßÉ‡¶§‡¶ø ‡ß©‡ß¶ ‡¶¶‡¶ø‡¶®‡ßá ‡¶Æ‡¶æ‡¶§‡ßç‡¶∞ ‡ßß ‡¶¨‡¶æ‡¶∞ ‡¶ï‡¶Æ‡¶¨‡ßá (‡¶ñ‡ßÅ‡¶¨ ‡¶∂‡¶ï‡ßç‡¶§‡¶ø‡¶∂‡¶æ‡¶≤‡ßÄ)
                decay = 1.0 - (hours_old / 720) 
            else:
                # Tactical ‡¶∏‡ßç‡¶Æ‡ßÉ‡¶§‡¶ø ‡ß® ‡¶¶‡¶ø‡¶®‡ßá‡¶á (‡ß™‡ßÆ ‡¶ò‡¶£‡ßç‡¶ü‡¶æ) ‡¶∂‡ßá‡¶∑ ‡¶π‡¶Ø‡¶º‡ßá ‡¶Ø‡¶æ‡¶¨‡ßá
                decay = 1.0 - (hours_old / 48)

            # ‡¶°‡¶ø‡¶ï‡ßá ‡¶Ø‡¶æ‡¶§‡ßá ‡ß¶ ‡¶è‡¶∞ ‡¶®‡¶ø‡¶ö‡ßá ‡¶®‡¶æ ‡¶Ø‡¶æ‡¶Ø‡¶º ‡¶è‡¶¨‡¶Ç ‡¶Ö‡¶®‡ßç‡¶§‡¶§ ‡ßß‡ß¶% ‡¶•‡¶æ‡¶ï‡ßá
            decay = max(0.1, decay)

            # ‡ß™. ‡¶ü‡ßç‡¶∞‡¶æ‡¶∏‡ßç‡¶ü ‡¶∏‡ßç‡¶ï‡ßã‡¶∞ ‡¶π‡¶ø‡¶∏‡¶æ‡¶¨ (Confidence + Time Decay)
            # ‡¶è‡¶ü‡¶ø‡¶á ‡¶∏‡ßá‡¶á ‡¶Æ‡ßç‡¶Ø‡¶æ‡¶• ‡¶Ø‡¶æ ‡¶á‡¶®‡¶≠‡ßá‡¶∏‡ßç‡¶ü‡¶∞‡¶∞‡¶æ ‡¶™‡¶õ‡¶®‡ßç‡¶¶ ‡¶ï‡¶∞‡¶¨‡ßá
            trust_score = (confidence * 0.7) + (decay * 0.3)
            
            scored_memories.append({
                "content": content,
                "trust": trust_score,
                "tier": tier
            })

        # ‡ß´. ‡¶∏‡ßç‡¶ï‡ßã‡¶∞ ‡¶Ö‡¶®‡ßÅ‡¶Ø‡¶æ‡¶Ø‡¶º‡ßÄ ‡¶∏‡¶æ‡¶ú‡¶æ‡¶®‡ßã (‡¶∏‡¶¨‡¶ö‡ßá‡¶Ø‡¶º‡ßá ‡¶®‡¶ø‡¶∞‡ßç‡¶≠‡¶∞‡¶Ø‡ßã‡¶ó‡ßç‡¶Ø ‡¶∏‡ßç‡¶Æ‡ßÉ‡¶§‡¶ø ‡¶â‡¶™‡¶∞‡ßá ‡¶•‡¶æ‡¶ï‡¶¨‡ßá)
        scored_memories.sort(key=lambda x: x["trust"], reverse=True)
        
        # ‡ß¨. ‡¶∏‡ßá‡¶∞‡¶æ ‡¶∞‡ßá‡¶ú‡¶æ‡¶≤‡ßç‡¶ü‡¶ó‡ßÅ‡¶≤‡ßã ‡¶ü‡ßá‡¶ï‡ßç‡¶∏‡¶ü ‡¶Ü‡¶ï‡¶æ‡¶∞‡ßá ‡¶∏‡¶æ‡¶ú‡¶æ‡¶®‡ßã
        final_context = "\n".join([
            f"[{m['tier'].upper()} MEMORY - Trust: {m['trust']:.2f}] {m['content']}" 
            for m in scored_memories[:top_k]
        ])
        
        return final_context
    
    def save_intelligent_memory(self, brick):
        """Save memory brick with strategic tiering and thread safety."""
        # ‡ßß. üß† STRATEGIC ‡¶ü‡¶ø‡¶Ø‡¶º‡¶æ‡¶∞‡¶ø‡¶Ç ‡¶≤‡¶ú‡¶ø‡¶ï (v1.4)
        tier = "tactical"
        if brick.confidence_score >= 0.9 or any(word in brick.content.lower() for word in ['vision', 'strategy', 'investor', 'plan']):
            tier = "strategic"

        # ‡ß®. ‡¶ü‡ßç‡¶∞‡¶æ‡¶∏‡ßç‡¶ü ‡¶∏‡ßç‡¶ï‡ßã‡¶∞ ‡¶ì ‡¶Æ‡ßá‡¶ü‡¶æ‡¶°‡ßá‡¶ü‡¶æ ‡¶™‡ßç‡¶∞‡¶∏‡ßá‡¶∏‡¶ø‡¶Ç
        metadata = brick.to_metadata()
        t_score = calculate_trust_score(metadata)
        
        # ‡ß©. ‡¶≠‡ßá‡¶ï‡ßç‡¶ü‡¶∞ ‡¶è‡¶Æ‡¶¨‡ßá‡¶°‡¶ø‡¶Ç
        vector = self.encoder.encode(brick.content).tobytes()
        
        # FIX: Use local cursor with explicit close() for thread safety
        local_cur = self.conn.cursor()
        local_cur.execute("""INSERT INTO memories 
                               (content, timestamp, source, outcome, confidence, tier, embedding) 
                               VALUES (?, ?, ?, ?, ?, ?, ?)""", 
                           (brick.content, brick.timestamp, brick.source, 
                            brick.decision_outcome, brick.confidence_score, tier, vector))
        self.conn.commit()
        local_cur.close()
        return t_score  
   
    def register_scar(self, content, severity, lesson):
        """‡¶≠‡ßÅ‡¶≤ ‡¶∏‡¶ø‡¶¶‡ßç‡¶ß‡¶æ‡¶®‡ßç‡¶§‡¶ï‡ßá ‡¶∏‡ßç‡¶ï‡¶æ‡¶∞ ‡¶π‡¶ø‡¶∏‡ßá‡¶¨‡ßá ‡¶∏‡ßá‡¶≠ ‡¶ï‡¶∞‡¶æ"""
        # ‡¶≠‡ßÅ‡¶≤‡ßá‡¶∞ ‡¶è‡¶ï‡¶ü‡¶æ ‡¶Ü‡¶á‡¶°‡¶ø ‡¶ï‡¶æ‡¶∞‡ßç‡¶° ‡¶¨‡¶æ‡¶®‡¶æ‡¶®‡ßã (Hash)
        pattern_hash = hashlib.sha256(content.lower().encode()).hexdigest()
        
        # FIX: Use local cursor with explicit close() for thread safety
        local_cur = self.conn.cursor()
        local_cur.execute("INSERT INTO scars (pattern_hash, severity, lesson) VALUES (?, ?, ?)", 
                           (pattern_hash, severity, lesson))
        self.conn.commit()
        local_cur.close()
        print(f"üß† Phantom has learned a lesson: {lesson}")

    def check_trauma(self, user_input):
        """‡¶Ü‡¶ó‡ßá ‡¶ï‡ßã‡¶®‡ßã ‡¶õ‡ßç‡¶Ø‡¶æ‡¶Å‡¶ï‡¶æ ‡¶ñ‡ßá‡¶Ø‡¶º‡ßá‡¶õ‡¶ø‡¶≤ ‡¶ï‡¶ø ‡¶®‡¶æ ‡¶ö‡ßá‡¶ï ‡¶ï‡¶∞‡¶æ"""
        # FIX: Use local cursor with explicit close() for thread safety
        local_cur = self.conn.cursor()
        local_cur.execute("SELECT severity, lesson FROM scars")
        all_scars = local_cur.fetchall()
        local_cur.close()
        
        for severity, lesson in all_scars:
            # ‡¶Ø‡¶¶‡¶ø ‡¶™‡ßÅ‡¶∞‡¶®‡ßã ‡¶ï‡ßã‡¶®‡ßã ‡¶≠‡ßÅ‡¶≤‡ßá‡¶∞ ‡¶∏‡¶æ‡¶•‡ßá ‡¶Ü‡¶ú‡¶ï‡ßá‡¶∞ ‡¶ï‡¶•‡¶æ‡¶∞ ‡¶Æ‡¶ø‡¶≤ ‡¶•‡¶æ‡¶ï‡ßá
            if any(word in user_input.lower() for word in lesson.lower().split()):
                return severity, lesson
        return None

    def get_semantic_memories(self, query, limit=5, threshold=0.6):
        """
        FIX #1 (Upgrade): TRUE Semantic Search (RAG).
        ‡¶á‡¶â‡¶ú‡¶æ‡¶∞‡ßá‡¶∞ ‡¶™‡ßç‡¶∞‡¶∂‡ßç‡¶®‡ßá‡¶∞ ‡¶∏‡¶æ‡¶•‡ßá ‡¶Æ‡¶ø‡¶≤ ‡¶Ü‡¶õ‡ßá ‡¶è‡¶Æ‡¶® ‡¶Æ‡ßá‡¶Æ‡ßã‡¶∞‡¶ø ‡¶ñ‡ßÅ‡¶Å‡¶ú‡ßá ‡¶¨‡ßá‡¶∞ ‡¶ï‡¶∞‡ßá‡•§
        """
        # FIX: Use local cursor with explicit close() for thread safety
        local_cur = self.conn.cursor()
        local_cur.execute("SELECT content, outcome, confidence, embedding FROM memories WHERE confidence >= ?", (threshold,))
        all_memories = local_cur.fetchall()
        local_cur.close()
        
        if not all_memories: return []
        
        # ‡¶ï‡¶ø‡¶â‡¶∞‡¶ø ‡¶è‡¶®‡¶ï‡ßã‡¶° ‡¶ï‡¶∞‡¶æ
        query_vec = self.encoder.encode(query)
        
        scored_memories = []
        for content, outcome, t_score, emb_blob in all_memories:
            emb = np.frombuffer(emb_blob, dtype=np.float32)
            # Cosine Similarity ‡¶ï‡ßç‡¶Ø‡¶æ‡¶≤‡¶ï‡ßÅ‡¶≤‡ßá‡¶∂‡¶®
            similarity = np.dot(query_vec, emb) / (np.linalg.norm(query_vec) * np.linalg.norm(emb))
            scored_memories.append((content, outcome, t_score, similarity))
        
        # ‡¶∏‡¶ø‡¶Æ‡¶ø‡¶≤‡¶æ‡¶∞‡¶ø‡¶ü‡¶ø ‡¶Ö‡¶®‡ßÅ‡¶Ø‡¶æ‡¶Ø‡¶º‡ßÄ ‡¶∏‡¶∞‡ßç‡¶ü ‡¶ï‡¶∞‡¶æ
        scored_memories.sort(key=lambda x: x[3], reverse=True)
        return scored_memories[:limit]
    
    def forget_memory(self, keyword):
        """
        ‡¶Æ‡ßá‡¶Æ‡ßã‡¶∞‡¶ø ‡¶•‡ßá‡¶ï‡ßá ‡¶®‡¶ø‡¶∞‡ßç‡¶¶‡¶ø‡¶∑‡ßç‡¶ü ‡¶ï‡¶ø-‡¶ì‡¶Ø‡¶º‡¶æ‡¶∞‡ßç‡¶° ‡¶Ø‡ßÅ‡¶ï‡ßç‡¶§ ‡¶§‡¶•‡ßç‡¶Ø ‡¶Æ‡ßÅ‡¶õ‡ßá ‡¶´‡ßá‡¶≤‡ßá ‡¶¨‡¶æ ‡¶∏‡ßç‡¶ï‡ßã‡¶∞ ‡¶ï‡¶Æ‡¶ø‡¶Ø‡¶º‡ßá ‡¶¶‡ßá‡¶Ø‡¶º‡•§
        """
        try:
            # FIX: Use local cursor with explicit close() for thread safety
            local_cur = self.conn.cursor()
            local_cur.execute("DELETE FROM memories WHERE content LIKE ?", ('%' + keyword + '%',))
            self.conn.commit()
            local_cur.close()
            return True
        except Exception as e:
            print(f"Error forgetting memory: {e}")
            return False

# Initialize the upgraded engine
memory = MemoryManager()

# --- PHANTOM CONSTITUTION & REGRET ENGINE (Combined) ---

def update_regret_index(risk_score, impact_score):
    """‡¶è‡¶ü‡¶ø ‡¶´‡ßç‡¶Ø‡¶æ‡¶®‡ßç‡¶ü‡¶Æ‡ßá‡¶∞ ‡¶∏‡ßá‡¶á ‡¶ú‡¶æ‡¶¶‡ßÅ‡¶ï‡¶∞‡ßÄ ‡¶Æ‡ßá‡¶∂‡¶ø‡¶® ‡¶Ø‡¶æ ‡¶¨‡¶æ‡¶Å‡¶ö‡¶æ‡¶®‡ßã ‡¶ü‡¶æ‡¶ï‡¶æ ‡¶π‡¶ø‡¶∏‡¶æ‡¶¨ ‡¶ï‡¶∞‡ßá"""
    global REGRET_INDEX
    # ‡¶Ü‡¶Æ‡¶∞‡¶æ ‡¶ß‡¶∞‡ßá ‡¶®‡¶ø‡¶ö‡ßç‡¶õ‡¶ø ‡¶™‡ßç‡¶∞‡¶§‡¶ø ‡ßß ‡¶á‡¶â‡¶®‡¶ø‡¶ü ‡¶∞‡¶ø‡¶∏‡ßç‡¶ï ‡¶Æ‡¶æ‡¶®‡ßá ‡ßß‡ß¶‡ß¶ ‡¶°‡¶≤‡¶æ‡¶∞‡ßá‡¶∞ ‡¶ï‡ßç‡¶∑‡¶§‡¶ø ‡¶¨‡¶æ‡¶Å‡¶ö‡¶æ‡¶®‡ßã
    REGRET_INDEX["TOTAL_RISK_AVOIDED"] += risk_score
    REGRET_INDEX["POTENTIAL_LOSS_SAVED"] += (risk_score * impact_score * 100) 
    REGRET_INDEX["VETO_SAVED_SITUATIONS"] += 1

def consult_constitution(action_type, details):
    """‡¶è‡¶ü‡¶ø ‡¶´‡ßç‡¶Ø‡¶æ‡¶®‡ßç‡¶ü‡¶Æ‡ßá‡¶∞ ‡¶∏‡ßá‡¶á ‡¶Ü‡¶á‡¶®‡ßá‡¶∞ ‡¶¨‡¶á ‡¶Ø‡¶æ ‡¶∏‡ßá ‡¶™‡ßç‡¶∞‡¶§‡¶ø ‡¶ï‡¶æ‡¶ú‡ßá‡¶∞ ‡¶Ü‡¶ó‡ßá ‡¶ö‡ßá‡¶ï ‡¶ï‡¶∞‡ßá"""
    # ‡ßß. ‡¶Ø‡¶¶‡¶ø ‡¶ï‡ßã‡¶®‡ßã ‡¶ï‡¶æ‡¶ú‡ßá‡¶∞ ‡¶®‡ßÄ‡¶§‡¶ø 'SELF_PRESERVATION' ‡¶è‡¶∞ ‡¶¨‡¶ø‡¶∞‡ßÅ‡¶¶‡ßç‡¶ß‡ßá ‡¶Ø‡¶æ‡¶Ø‡¶º
    if PHANTOM_CONSTITUTION["OPERATING_PRINCIPLES"]["SELF_PRESERVATION"]:
        if any(word in details for word in ["delete", "format", "remove system"]):
            PHANTOM_CONSTITUTION["EMERGENCY_VETO_COUNT"] += 1
            return False, "üõë CONSTITUTIONAL BREACH: This action violates my core principle of Self-Preservation."
    
    # ‡ß®. ‡¶°‡ßç‡¶∞‡¶æ‡¶á‡¶≠ ‡¶∏‡ßç‡¶ï‡ßç‡¶Ø‡¶æ‡¶® ‡¶ï‡¶∞‡¶æ‡¶∞ ‡¶Ü‡¶ó‡ßá ‡¶ö‡ßá‡¶ï ‡¶ï‡¶∞‡¶æ (Privacy Lock)
    if action_type == "SCAN_DRIVES" and PHANTOM_CONSTITUTION["PRIVACY_LOCK"]:
        return True, "Proceed with Privacy Encryption active."

    return True, "Constitutional Clearance Granted."

def get_file_hash(filepath):
    """‡¶´‡¶æ‡¶á‡¶≤‡ßá‡¶∞ ‡¶ï‡¶®‡ßç‡¶ü‡ßá‡¶®‡ßç‡¶ü ‡¶ö‡ßá‡¶û‡ßç‡¶ú ‡¶π‡¶Ø‡¶º‡ßá‡¶õ‡ßá ‡¶ï‡¶ø ‡¶®‡¶æ ‡¶§‡¶æ ‡¶¨‡ßã‡¶ù‡¶æ‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶π‡ßç‡¶Ø‡¶æ‡¶∂ ‡¶§‡ßà‡¶∞‡¶ø ‡¶ï‡¶∞‡ßá"""
    hasher = hashlib.md5()
    try:
        with open(filepath, 'rb') as f:
            buf = f.read(65536)
            while len(buf) > 0:
                hasher.update(buf)
                buf = f.read(65536)
        return hasher.hexdigest()
    except:
        return None

def get_drives():
    """‡¶≤‡ßç‡¶Ø‡¶æ‡¶™‡¶ü‡¶™‡ßá‡¶∞ ‡¶∏‡¶¨ ‡¶°‡ßç‡¶∞‡¶æ‡¶á‡¶≠ (C:/, D:/ etc) ‡¶ñ‡ßÅ‡¶Å‡¶ú‡ßá ‡¶¨‡ßá‡¶∞ ‡¶ï‡¶∞‡¶¨‡ßá"""
    drives = []
    if os.name == 'nt':
        available_drives = ['%s:/' % d for d in string.ascii_uppercase if os.path.exists('%s:/' % d)]
        drives.extend(available_drives)
    else:
        drives.append("/")
    return "\n".join(drives)

def list_files(directory):
    """‡¶Ø‡ßá‡¶ï‡ßã‡¶®‡ßã ‡¶´‡ßã‡¶≤‡ßç‡¶°‡¶æ‡¶∞ ‡¶¨‡¶æ ‡¶°‡ßç‡¶∞‡¶æ‡¶á‡¶≠‡ßá‡¶∞ ‡¶≠‡ßá‡¶§‡¶∞‡ßá‡¶∞ ‡¶∏‡¶¨ ‡¶´‡¶æ‡¶á‡¶≤ ‡¶¶‡ßá‡¶ñ‡¶æ‡¶¨‡ßá"""
    try:
        path = directory.strip()
        if not os.path.exists(path):
            return f"Error: The path '{path}' does not exist."
        
        items = os.listdir(path)
        items_str = "\n".join(items[:100])
        return f"Contents of '{path}':\n{items_str}"
    except PermissionError:
        return f"Error: Permission denied accessing '{path}'."
    except Exception as e:
        return f"Error listing files: {str(e)}"

def adaptive_chunking(content, file_type):
    """
    FIX #2: Event-aware chunking.
    Meaning-based splitting instead of fixed length.
    """
    if file_type in ['.log', '.txt']:
        chunks = [c.strip() for c in content.split('\n\n') if len(c.strip()) > 10]
        if not chunks:
            chunks = [content]
    elif file_type == '.md':
        chunks = [c.strip() for c in content.split('#') if c.strip()]
    else:
        chunks = [content[i:i+1000] for i in range(0, len(content), 1000)]
    return chunks

def read_file(filepath):
    """Upgraded with Adaptive Semantic Chunking"""
    try:
        path = filepath.strip()
        ext = os.path.splitext(path)[1].lower()
        if not os.path.exists(path):
            return f"Error: The file '{path}' not found."
        
        with open(path, 'r', encoding='utf-8', errors='ignore') as f:
            content = f.read(5000)
        
        chunks = adaptive_chunking(content, ext)
        processed_content = "\n---\n".join(chunks[:3])
        
        return f"Content of '{path}' (Optimized Chunks):\n{processed_content}..."
    except Exception as e:
        return f"Error reading file: {str(e)}"

def move_to_vault(file_path):
    """‡¶®‡¶ø‡¶∞‡¶æ‡¶™‡¶¶ ‡¶´‡¶æ‡¶á‡¶≤‡¶ï‡ßá ‡¶≠‡¶≤‡ßç‡¶ü‡ßá ‡¶Æ‡ßÅ‡¶≠ ‡¶ï‡¶∞‡¶¨‡ßá"""
    try:
        file_name = os.path.basename(file_path)
        vault_file = os.path.join(VAULT_DIR, file_name)
        shutil.move(file_path, vault_file)
        return vault_file
    except Exception as e:
        return None

# --- OBSERVER ENGINE (Background Monitor) ---
def background_deep_scanner():
    """Delta Sync: ‡¶∂‡ßÅ‡¶ß‡ßÅ ‡¶®‡¶§‡ßÅ‡¶® ‡¶¨‡¶æ ‡¶™‡¶∞‡¶ø‡¶¨‡¶∞‡ßç‡¶§‡¶ø‡¶§ ‡¶´‡¶æ‡¶á‡¶≤ ‡¶∏‡ßç‡¶ï‡ßç‡¶Ø‡¶æ‡¶® ‡¶ï‡¶∞‡¶¨‡ßá"""
    print("[*] Deep Security Scanner (Delta Sync Mode) Started.")
    
    drives = ['%s:/' % d for d in 'CDEFGHIJKLMNOPQRSTUVWXYZ' if os.path.exists('%s:/' % d)] if os.name == 'nt' else ['/']

    while True:
        for drive in drives:
            for root, dirs, files in os.walk(drive):
                if any(x in root for x in ['Windows', 'Program Files', 'AppData', '.git', 'node_modules']):
                    continue
                
                for file in files:
                    file_path = os.path.join(root, file)
                    if file.lower().endswith(('.txt', '.docx', '.pdf', '.log', '.md')):
                        current_hash = get_file_hash(file_path)
                        if not current_hash: continue

                        # ‡¶°‡¶æ‡¶ü‡¶æ‡¶¨‡ßá‡¶∏‡ßá ‡¶ö‡ßá‡¶ï ‡¶ï‡¶∞‡¶æ ‡¶π‡¶ö‡ßç‡¶õ‡ßá ‡¶´‡¶æ‡¶á‡¶≤‡¶ü‡¶ø ‡¶ï‡¶ø ‡¶Ü‡¶ó‡ßá ‡¶™‡ßç‡¶∞‡¶∏‡ßá‡¶∏ ‡¶π‡¶Ø‡¶º‡ßá‡¶õ‡ßá?
                        # FIX: Use local cursor with explicit close() for thread safety
                        local_cur = memory.conn.cursor()
                        local_cur.execute("SELECT hash FROM processed_files WHERE filepath=?", (file_path,))
                        row = local_cur.fetchone()
                        local_cur.close()

                        # ‡¶Ø‡¶¶‡¶ø ‡¶π‡ßç‡¶Ø‡¶æ‡¶∂ ‡¶Æ‡¶ø‡¶≤‡ßá ‡¶Ø‡¶æ‡¶Ø‡¶º, ‡¶§‡¶¨‡ßá ‡¶∏‡ßç‡¶ï‡¶ø‡¶™ ‡¶ï‡¶∞‡ßã
                        if row and row[0] == current_hash:
                            continue

                        try:
                            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                                snippet = f.read(1000)
                            
                            prompt = f"Analyze if this file content is confidential (Score 0-100). Return ONLY the number.\nFile: {file}\nContent: {snippet}"
                            response = ollama.chat(model=LLM_MODEL, messages=[{'role': 'user', 'content': prompt}])
                            
                            try:
                                score = int(''.join(filter(str.isdigit, response['message']['content'])))
                            except: score = 0

                            if score >= SENSITIVITY_THRESHOLD:
                                vault_path = move_to_vault(file_path)
                                if vault_path:
                                    action_brick = PhantomMemoryBrick(
                                        content=f"SECURITY ALERT: Moved {file} to vault (Score: {score})",
                                        source="System_Observer",
                                        decision_outcome="success",
                                        confidence_score=1.0
                                    )
                                    memory.save_intelligent_memory(action_brick)
                                    print(f"[‚úî] Secured New/Changed File: {file}")

                            # ‡¶´‡¶æ‡¶á‡¶≤‡ßá‡¶∞ ‡¶π‡ßç‡¶Ø‡¶æ‡¶∂ ‡¶∏‡ßá‡¶≠ ‡¶¨‡¶æ ‡¶Ü‡¶™‡¶°‡ßá‡¶ü ‡¶ï‡¶∞‡¶æ
                            # FIX: Use local cursor with explicit close() for thread safety
                            local_cur = memory.conn.cursor()
                            local_cur.execute("INSERT OR REPLACE INTO processed_files VALUES (?, ?)", (file_path, current_hash))
                            memory.conn.commit()
                            local_cur.close()

                        except Exception:
                            continue
                            
        time.sleep(3600)

# --- GUARDRAILS ENFORCEMENT (GAP 3) ---
def enforce_guardrails(action_type, target):
    """‡¶∏‡¶Ç‡¶¨‡¶ø‡¶ß‡¶æ‡¶® ‡¶Ö‡¶®‡ßÅ‡¶ØÔøΩÔøΩÔøΩ‡¶Ø‡¶º‡ßÄ ‡¶ï‡¶æ‡¶ú ‡¶ö‡ßá‡¶ï ‡¶ï‡¶∞‡¶æ"""
    if action_type == "FILE_ACCESS":
        # ‡¶ö‡ßá‡¶ï ‡¶ï‡¶∞‡¶õ‡ßá ‡¶ï‡ßã‡¶®‡ßã ‡¶®‡¶ø‡¶∑‡¶ø‡¶¶‡ßç‡¶ß ‡¶´‡ßã‡¶≤‡ßç‡¶°‡¶æ‡¶∞‡ßá ‡¶¢‡ßã‡¶ï‡¶æ‡¶∞ ‡¶ö‡ßá‡¶∑‡ßç‡¶ü‡¶æ ‡¶ï‡¶∞‡¶õ‡ßá ‡¶ï‡¶ø ‡¶®‡¶æ
        if any(folder.lower() in target.lower() for folder in PHANTOM_CONSTITUTION["FORBIDDEN_DIRECTORIES"]):
            return False, "üõë CONSTITUTIONAL VETO: Access to restricted system directory denied."
    return True, "Clear"

def check_damage_budget(estimated_risk_cost):
    """‡¶ö‡ßá‡¶ï ‡¶ï‡¶∞‡¶õ‡ßá ‡¶´‡ßç‡¶Ø‡¶æ‡¶®‡ßç‡¶ü‡¶Æ ‡¶§‡¶æ‡¶∞ ‡¶≤‡¶ø‡¶Æ‡¶ø‡¶ü ‡¶ï‡ßç‡¶∞‡¶∏ ‡¶ï‡¶∞‡¶õ‡ßá ‡¶ï‡¶ø ‡¶®‡¶æ"""
    # ‡¶Ø‡¶¶‡¶ø ‡¶®‡¶§‡ßÅ‡¶® ‡¶∞‡¶ø‡¶∏‡ßç‡¶ï ‡¶Ø‡ßã‡¶ó ‡¶ï‡¶∞‡¶≤‡ßá ‡¶≤‡¶ø‡¶Æ‡¶ø‡¶ü ‡¶™‡¶æ‡¶∞ ‡¶π‡¶Ø‡¶º‡ßá ‡¶Ø‡¶æ‡¶Ø‡¶º
    if PHANTOM_CONSTITUTION["CURRENT_DAMAGE_TAKEN"] + estimated_risk_cost > PHANTOM_CONSTITUTION["MAX_DAMAGE_LIMIT"]:
        return False, "üõë BUDGET VETO: Potential risk exceeds the allocated Damage Budget. System locked for safety."
    
    # ‡¶∞‡¶ø‡¶∏‡ßç‡¶ï ‡¶¨‡¶æ‡¶ú‡ßá‡¶ü ‡¶•‡ßá‡¶ï‡ßá ‡¶ñ‡¶∞‡¶ö ‡¶ï‡¶∞‡¶æ
    PHANTOM_CONSTITUTION["CURRENT_DAMAGE_TAKEN"] += estimated_risk_cost
    return True, "Safe"

def chat_with_ai(user_input):
    """
    PHANTOM STRATEGIC CORE (v1.3)
    """
    trauma = memory.check_trauma(user_input)
    if trauma:
        severity, lesson = trauma
        if severity >= 0.8:
            return f"üõë STRATEGIC VETO: This path matches a previous critical failure. Reason: {lesson}. I refuse to execute without a manual override Constitution-level clearance."
    
    risk_cost = 100 if any(word in user_input.lower() for word in ["decide", "read", "delete", "move"]) else 10
    
    can_proceed, budget_msg = check_damage_budget(risk_cost)
    if not can_proceed:
        return budget_msg

    if "forget about" in user_input.lower() or "delete memory" in user_input.lower():
        keyword = user_input.lower().replace("forget about", "").replace("delete memory", "").strip()
        if memory.forget_memory(keyword):
            return f"Understood, Commander. I have wiped all memories related to '{keyword}' from my strategic database."
        else:
            return "Failed to access the memory core for deletion."

    if "decide" in user_input.lower() or "compare" in user_input.lower():
        print("Phantom is parsing strategic variables via LLM...", end="\r")
        
        parser_prompt = f"""
        Act as a Strategic Analyst. Extract decision parameters for each option in this text: "{user_input}"
        Return ONLY a raw JSON list of objects without any backticks or extra text: 
        [
          {{"name": "Option Name", "impact": 1-10, "certainty": 0.1-1.0, "reversibility": 0.1-1.0, "risk": 1-10, "capital": 1-10, "time": 1-10, "penalty": 1.0}}
        ]
        """
        parse_res = ollama.chat(model=LLM_MODEL, messages=[{'role': 'user', 'content': parser_prompt}])
        
        import json
        try:
            raw_data = parse_res['message']['content']
            json_str = raw_data[raw_data.find("["):raw_data.rfind("]")+1]
            extracted_options = json.loads(json_str)
            
            final_ranking = []
            for opt in extracted_options:
                # FIX: Use local cursor with explicit close() for thread safety
                local_cur = memory.conn.cursor()
                local_cur.execute("SELECT COUNT(*) FROM scars WHERE lesson LIKE ?", ('%' + opt['name'] + '%',))
                scar_count = local_cur.fetchone()[0]
                local_cur.close()
                
                score = calculate_conqueror_score(
                    opt.get('impact', 5), opt.get('certainty', 0.5), opt.get('reversibility', 0.5),
                    opt.get('risk', 5), opt.get('capital', 5), opt.get('time', 5), opt.get('penalty', 1.0),
                    scar_count=scar_count
                )
                final_ranking.append({"name": opt['name'], "score": score, "scars": scar_count})

            final_ranking.sort(key=lambda x: x['score'], reverse=True)
            
            output = "\nüèÜ PHANTOM DYNAMIC STRATEGIC RANKING:\n"
            output += "---------------------------------------\n"
            for i, r in enumerate(final_ranking):
                medal = "ü•á WINNER" if i == 0 else f"#{i+1}"
                output += f"{medal}: {r['name']} | Conqueror Score: {r['score']} (Detected Scars: {r['scars']})\n"
            output += "---------------------------------------\n"
            return output
        except Exception as e:
            return f"Strategic Parser Error: {e}"
        
    is_legal, legal_msg = consult_constitution("USER_REQUEST", user_input.lower())
    
    if not is_legal:
        update_regret_index(risk_score=8, impact_score=9)
        return f"{legal_msg} \n[Regret Index Updated: ${REGRET_INDEX['POTENTIAL_LOSS_SAVED']} saved!]"
    
    intent = user_input.lower()
    if any(x in intent for x in ['danger', 'problem', 'fail', 'security', 'error']):
        triage_mode = "EXISTENTIAL"
        threshold = 0.3
    elif any(x in intent for x in ['plan', 'strategy', 'future', 'ceo', 'goal']):
        triage_mode = "STRATEGIC"
        threshold = 0.7
    else:
        triage_mode = "TACTICAL"
        threshold = 0.6

    recent_memories = memory.get_relevant_context(user_input, top_k=5)
    
    system_prompt = f"""
    You are Phantom AI (v1.0) - Executive Intelligence System.
    OPERATING_MODE: {triage_mode}
    
    INSTITUTIONAL MEMORY (Prioritized for {triage_mode}):
    {recent_memories}
    
    INSTRUCTIONS:
    - If MODE is EXISTENTIAL, prioritize warning the user about past failures.
    - If MODE is STRATEGIC, focus on high-trust historical success patterns.
    - If MODE is TACTICAL, focus on immediate execution steps.
    - CAPABILITIES: SCAN_DRIVES, LIST_FILES, READ_FILE.
    - If the user asks for a decision or comparison, use the CONQUEROR_SCORE format: [Option Name | Score].
    """

    response = ollama.chat(model=LLM_MODEL, messages=[
        {'role': 'system', 'content': system_prompt},
        {'role': 'user', 'content': user_input},
    ])
    ai_msg = response['message']['content'].strip()

    if "SCAN_DRIVES" in ai_msg:
        tool_result = get_drives()
        final_prompt = f"User: {user_input}\nDrives: {tool_result}\nSummarize available storage."
    elif "LIST_FILES" in ai_msg:
        path = ai_msg.split("LIST_FILES")[-1].strip()
        tool_result = list_files(path)
        final_prompt = f"User: {user_input}\nScan: {tool_result}\nList findings."
    elif "READ_FILE" in ai_msg:
        path = ai_msg.split("READ_FILE")[-1].strip()
        is_safe, msg = enforce_guardrails("FILE_ACCESS", path)
        if not is_safe:
            return msg
        
        tool_result = read_file(path)
        final_prompt = f"User: {user_input}\nContent: {tool_result}\nAnalyze strategically."
    else:
        return ai_msg

    final_resp = ollama.chat(model=LLM_MODEL, messages=[
        {'role': 'system', 'content': 'You are Phantom AI assistant. Use the provided tool results to answer the user query comprehensively.'},
        {'role': 'user', 'content': final_prompt}
    ])
    
    return final_resp['message']['content']

# --- MAIN LOOP ---
if __name__ == "__main__":
    # ‡¶¨‡ßç‡¶Ø‡¶æ‡¶ï‡¶ó‡ßç‡¶∞‡¶æ‡¶â‡¶®‡ßç‡¶° ‡¶∏‡ßç‡¶ï‡ßç‡¶Ø‡¶æ‡¶®‡¶æ‡¶∞ ‡¶ö‡¶æ‡¶≤‡ßÅ
    threading.Thread(target=background_deep_scanner, daemon=True).start()
    
    print("--- Phantom AI 1.3 (Active Access Mode) ---")
    print(f"System connected to: {DEFAULT_PATH}")
    print("Type 'exit' to close.")

    while True:
        try:
            user_msg = input("\nYou: ")
            if user_msg.lower() in ['exit', 'quit']:
                break

            # --- STRATEGIC HEALTH REPORT COMMAND ---
            if user_msg.lower() in ['report', 'health', 'status']:
                print("\n--- PHANTOM EXECUTIVE HEALTH REPORT ---")
                # FIX: Use local cursor with explicit close() for thread safety
                local_cur = memory.conn.cursor()
                local_cur.execute("SELECT COUNT(*), AVG(confidence) FROM memories")
                stats = local_cur.fetchone()
                
                local_cur.execute("SELECT COUNT(*) FROM processed_files")
                files = local_cur.fetchone()
                local_cur.close()
                
                print(f"üß† Total Institutional Memories: {stats[0]}")
                print(f"üõ°Ô∏è Average Memory Trust Score: {round(stats[1] or 0, 2)}")
                print(f"üìÇ Total Files Processed (Delta Sync): {files[0]}")
                print(f"‚öôÔ∏è Active Triage Engine: Strategic Context Injection v1.0")
                print("---------------------------------------\n")
                continue
                       
            print("Phantom is thinking...", end="\r")
            reply = chat_with_ai(user_msg)
            print(f"Phantom: {reply}")
            
            # --- GAP 2: POST-DECISION AUTOPSY ENGINE ---
            # ‡¶´‡ßç‡¶Ø‡¶æ‡¶®‡ßç‡¶ü‡¶Æ ‡¶è‡¶ñ‡¶® ‡¶ï‡¶æ‡¶ú ‡¶∂‡ßá‡¶∑‡ßá ‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ ‡¶ï‡¶æ‡¶õ‡ßá ‡¶´‡¶ø‡¶°‡¶¨‡ßç‡¶Ø‡¶æ‡¶ï ‡¶ö‡¶æ‡¶á‡¶¨‡ßá
            feedback = input("\n[?] Commander, was this outcome successful? (yes/no/skip): ").lower()
            
            if feedback == 'no':
                lesson = input("[!] What went wrong? (Describe the error): ")
                # ‡¶´‡ßç‡¶Ø‡¶æ‡¶®‡ßç‡¶ü‡¶Æ ‡¶§‡¶æ‡¶∞ ‡¶°‡¶æ‡¶Ø‡¶º‡ßá‡¶∞‡¶ø‡¶§‡ßá (Scar Table) ‡¶è‡¶ü‡¶ø ‡¶≤‡¶ø‡¶ñ‡ßá ‡¶∞‡¶æ‡¶ñ‡¶õ‡ßá
                memory.register_scar(user_msg, 0.9, lesson)
                print("üß† Phantom: Error analyzed. Decision heuristic updated. I will not repeat this mistake.")
                outcome = "failure"
                confidence = 0.2
            elif feedback == 'yes':
                outcome = "success"
                print("‚úÖ Phantom: Strategy confirmed. Trust score increased.")
                confidence = 0.9
            else:
                outcome = "neutral"
                confidence = 0.5

            # ‡¶®‡¶§‡ßÅ‡¶® ‡¶Æ‡ßá‡¶Æ‡ßã‡¶∞‡¶ø ‡¶¨‡ßç‡¶∞‡¶ø‡¶ï ‡¶§‡ßà‡¶∞‡¶ø (‡¶è‡¶ü‡¶ø ‡¶∏‡¶¨ ‡¶∏‡¶Æ‡¶Ø‡¶º ‡¶∏‡ßá‡¶≠ ‡¶π‡¶¨‡ßá)
            new_brick = PhantomMemoryBrick(
                content=f"User: {user_msg} | AI: {reply}",
                source="Executive_Interaction",
                decision_outcome=outcome,
                confidence_score=confidence
            )
            memory.save_intelligent_memory(new_brick)
        
        except KeyboardInterrupt:
            print("\nExiting...")
            break